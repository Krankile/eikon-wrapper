{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e7868a6",
   "metadata": {
    "id": "3e7868a6"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "9e4198ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e4198ca",
    "outputId": "b68a3433-3c83-464a-a91c-8b6feec75965"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: eikon in c:\\users\\lla24\\anaconda3\\lib\\site-packages (1.1.15)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from eikon) (1.21.5)\n",
      "Requirement already satisfied: idna==2.* in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from eikon) (2.10)\n",
      "Requirement already satisfied: requests==2.* in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from eikon) (2.27.1)\n",
      "Requirement already satisfied: datetime in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from eikon) (4.5)\n",
      "Requirement already satisfied: websocket-client!=1.0.0,>=0.54.0 in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from eikon) (0.58.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from eikon) (2.8.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from eikon) (2021.10.8)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from eikon) (1.4.2)\n",
      "Requirement already satisfied: h2==3.* in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from eikon) (3.2.0)\n",
      "Requirement already satisfied: httpx>=0.18.0 in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from eikon) (0.23.0)\n",
      "Requirement already satisfied: deprecation in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from eikon) (2.1.0)\n",
      "Requirement already satisfied: rfc3986==1.* in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from eikon) (1.5.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from eikon) (1.4.4)\n",
      "Requirement already satisfied: chardet==3.* in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from eikon) (3.0.4)\n",
      "Requirement already satisfied: nest-asyncio>=1.5.1 in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from eikon) (1.5.5)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from h2==3.*->eikon) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from h2==3.*->eikon) (3.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from requests==2.*->eikon) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from requests==2.*->eikon) (2.0.4)\n",
      "Requirement already satisfied: httpcore<0.16.0,>=0.15.0 in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from httpx>=0.18.0->eikon) (0.15.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from httpx>=0.18.0->eikon) (1.2.0)\n",
      "Requirement already satisfied: anyio==3.* in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from httpcore<0.16.0,>=0.15.0->httpx>=0.18.0->eikon) (3.5.0)\n",
      "Requirement already satisfied: h11<0.13,>=0.11 in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from httpcore<0.16.0,>=0.15.0->httpx>=0.18.0->eikon) (0.12.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->eikon) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from python-dateutil->eikon) (1.16.0)\n",
      "Requirement already satisfied: zope.interface in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from datetime->eikon) (5.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from deprecation->eikon) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from packaging->deprecation->eikon) (3.0.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lla24\\anaconda3\\lib\\site-packages (from zope.interface->datetime->eikon) (61.2.0)\n",
      "Collecting more_itertools\n",
      "  Downloading more_itertools-8.13.0-py3-none-any.whl (51 kB)\n",
      "Installing collected packages: more-itertools\n",
      "Successfully installed more-itertools-8.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install eikon\n",
    "!pip install more_itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "b056c9a0",
   "metadata": {
    "id": "b056c9a0"
   },
   "outputs": [],
   "source": [
    "import eikon as ek\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "from more_itertools import chunked\n",
    "from math import ceil, floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd1e83d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bd1e83d4",
    "outputId": "8d1e523c-300f-4b45-b691-df05f0a69f54"
   },
   "outputs": [],
   "source": [
    "#\"api_key_lk\"\n",
    "ek.set_app_key(\"716a396b553b441680427f612d2f89735c88bf9e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32835af0",
   "metadata": {
    "id": "32835af0"
   },
   "source": [
    "## Screen companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bf666227",
   "metadata": {
    "id": "bf666227"
   },
   "outputs": [],
   "source": [
    "oil_osebx_screen = 'SCREEN(U(IN(Equity(active,public,primary))), TR.CompanyMarketCap>=500000, IN(TR.ExchangeMarketIdCode,\"XOSL\"), IN(TR.TRBCBusinessSectorCode,\"5010\",\"5020\",\"5030\"), CURN=USD)'\n",
    "company_names = [\"TR.CommonName\"]#[\"TR.CommonName\",\"TR.CompanyMarketCap\",\"TR.ExchangeName\",\"TR.TRBCBusinessSector\",\"TR.TotalReturn3Mo\"]\n",
    "\n",
    "osbx_companies, e = ek.get_data(oil_osebx_screen, company_names)\n",
    "osbx_companies = osbx_companies.set_index(\"Instrument\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "091dd0cf",
   "metadata": {
    "id": "091dd0cf"
   },
   "outputs": [],
   "source": [
    "oil_global_screen = 'SCREEN(U(IN(Equity(active,public,primary))), TR.CompanyMarketCap>=500000, IN(TR.TRBCBusinessSectorCode,\"5010\",\"5020\",\"5030\"), CURN=USD)'\n",
    "fields_oil_global_screen = [\"TR.CommonName\"]\n",
    "\n",
    "global_oil, e = ek.get_data(oil_global_screen, fields_oil_global_screen)\n",
    "global_oil = global_oil.set_index(\"Instrument\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "902ecdde",
   "metadata": {
    "id": "902ecdde"
   },
   "outputs": [],
   "source": [
    "financial_global_screen = 'SCREEN(U(IN(Equity(active,public,primary))), TR.CompanyMarketCap>=500000, IN(TR.TRBCBusinessSectorCode,\"5510\"), CURN=USD)'\n",
    "fields_financial_global_screen = [\"TR.CommonName\"]\n",
    "\n",
    "global_financial, e = ek.get_data(financial_global_screen, fields_financial_global_screen)\n",
    "global_financial = global_financial.set_index(\"Instrument\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ae7040",
   "metadata": {
    "id": "c0ae7040"
   },
   "source": [
    "Now we have dataframe of all noted oil companies (with mcap > USD 5m) in eikon refinitives entire database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926ea32f",
   "metadata": {
    "id": "926ea32f"
   },
   "source": [
    "## Below are some interesting fields regarding public companies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4814d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Market capitalization fields \n",
    "fields = ['TR.CompanyMarketCap.Date','TR.CompanyMarketCap', 'TR.PriceClose', 'TR.CompanyMarketCap.Currency'] \n",
    "\n",
    "#Fundamental stock data fields\n",
    "profits = ['TR.TotalRevenue', 'TR.GrossProfit','TR.EBITDA','TR.EBIT', 'TR.F.NetIncAfterTax']#, 'TR.EV','MKT_CAP']\n",
    "balance = ['TR.F.TotAssets','TR.F.TotCurrAssets','TR.F.TotLiab','TR.F.TotCurrLiab','TR.F.LTDebtPctofTotAssets','TR.F.STDebtPctofTotAssets',\"TR.InvtrPriceToBook\"]#TR.F.TotLiab(Period=FY0)\n",
    "cash_flow = ['TR.F.LeveredFOCF']\n",
    "\n",
    "fundamental_data = profits + balance + cash_flow \n",
    "reported_dates = ['TR.TotalRevenue.periodenddate']\n",
    "\n",
    "#Company meta data fields\n",
    "geography = ['TR.ExchangeMarketIdCode', 'TR.HeadquartersRegionAlt', 'TR.HeadquartersCountry', 'TR.HQStateProvince']\n",
    "sectors = ['TR.TRBCEconomicSector', 'TR.TRBCBusinessSector', 'TR.TRBCIndustryGroup', 'TR.TRBCIndustry', 'TR.TRBCActivity']\n",
    "founded = ['TR.OrgFoundedYear']\n",
    "\n",
    "meta_data = geography + founded + sectors\n",
    "\n",
    "#Broker estimates\n",
    "#params_new[\"Period\"] = \"FY1\"    \n",
    "    \n",
    "fields = [\"TR.EPSMean\",\"TR.EPSMean.periodenddate\",\"TR.EBITMean\",'TR.RevenueMean',\n",
    "              \"TR.ROAMean\",\"TR.ROEMean\",\"TR.FCFMean\",\"TR.TotalAssets\",\"TR.MeanPctChg(Period=FY1,WP=60d)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c52216",
   "metadata": {
    "id": "99c52216"
   },
   "source": [
    "# Collect data from eikon refinitiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7414cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _decide_get_function(fields, params):\n",
    "    \n",
    "    timeseries_fields = [\"TIMESTAMP\", \"VALUE\", \"VOLUME\", \"HIGH\", \"LOW\", \"OPEN\", \"CLOSE\", \"COUNT\"]\n",
    "    \n",
    "    if isinstance(fields, str):\n",
    "        fields = [fields]\n",
    "    \n",
    "    if all([field in timeseries_fields for field in fields]) or fields is None: \n",
    "         \n",
    "        return ek.get_timeseries\n",
    "    \n",
    "    if params[\"Frq\"] in [\"tick\", \"minute\", \"hour\"]:\n",
    "        raise ValueError(\"You requested data of ek.get_data() requesting timeperiods it does not support\")\n",
    "    \n",
    "    return ek.get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "427b77be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_params(chosen_function, params):\n",
    "    \n",
    "    if chosen_function == ek.get_timeseries:\n",
    "        params[\"start_date\"] = params[\"SDate\"]\n",
    "        params[\"end_date\"] = params[\"EDate\"]\n",
    "        params[\"interval\"] =  params[\"Frq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "613a96ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_many_params(params, date_range, chosen_function):\n",
    "    if date_range is not None:\n",
    "        params_copies = []       \n",
    "        for i in range(len(date_range)-1):\n",
    "            new_params = params.copy()\n",
    "            new_params[\"SDate\"] = date_range[i].strftime('%Y-%m-%d')\n",
    "            new_params[\"EDate\"] = date_range[i+1].strftime('%Y-%m-%d')\n",
    "            correct_params(new_params, chosen_function)\n",
    "            params_copies.append(new_params)\n",
    "        return params_copies\n",
    "    return [params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "76662523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _decide_tickers_and_params(chosen_function, fields, lst_of_tickers, params):\n",
    "    \n",
    "    data_limit = {ek.get_timeseries:2_500, ek.get_data:9_000}\n",
    "    date_range = None\n",
    "    tickers_params_pairs = []\n",
    "    \n",
    "    #If there this is not a timeseries problem\n",
    "    if \"SDate\" not in params.keys():\n",
    "        return lst_of_tickers\n",
    "    \n",
    "    number_of_timepoints = chosen_function(lst_of_tickers[0], fields[0], params)[0].shape[0]\n",
    "    print(f\"number_of_timepoints {number_of_timepoints}\")\n",
    "    \n",
    "    number_of_tickers_at_once = floor(data_limit[chosen_function] / (len(fields) * number_of_timepoints))\n",
    "    print(f\"number_of_tickers_at_once {number_of_tickers_at_once}\")\n",
    "    \n",
    "    if number_of_tickers_at_once < 1: \n",
    "        number_of_timepoints_at_once = floor(data_limit[chosen_function] / len(fields))\n",
    "        intervals_needed = ceil(number_of_timepoints / number_of_timepoints_at_once)\n",
    "        \n",
    "        time_delta = (pd.to_datetime(params[\"EDate\"]) - pd.to_datetime(params[\"SDate\"])) / intervals_needed\n",
    "        date_range = [pd.to_datetime(params[\"SDate\"]) + i*time_delta for i in range(intervals_needed-1)] + [pd.to_datetime(params[\"EDate\"])]\n",
    "        number_of_tickers_at_once = 1\n",
    "    \n",
    "    sub_ticker_lst = list(chunked(lst_of_tickers, number_of_tickers_at_once))\n",
    "    params_copies = _get_many_params(params, date_range, chosen_function)\n",
    "    \n",
    "    for sub_tickers in sub_ticker_lst:\n",
    "        for params_copy in params_copies:\n",
    "            tickers_params_pairs.append((sub_tickers, params_copy))\n",
    "            \n",
    "    \n",
    "    return tickers_params_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "8d27e297",
   "metadata": {
    "id": "8d27e297"
   },
   "outputs": [],
   "source": [
    "#Function to maximize data per http request. \n",
    "def _divide_pull_request(lst_of_tickers, fields, params):\n",
    "    #batch, deduce get_data or get_timeseries size given\n",
    "    #lst_of_tickers x fields x (params[start]-params[end])*freq < 10,000 or 3,000\n",
    "    #also adjust params so that they fit selected function \n",
    "    \n",
    "    chosen_function = _decide_get_function(fields, params)\n",
    "    params_adjusted = params\n",
    "    \n",
    "    tickers_params_pairs = _decide_tickers_and_params(chosen_function, fields, lst_of_tickers, params)#TODO\n",
    "    \n",
    "    return tickers_params_pairs, chosen_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "a3670730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_time(server_side_problems):\n",
    "    return 3**(server_side_problems-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "2c30c9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_and_update_server_side_problem(server_side_problems, err):\n",
    "    server_side_problems += 1\n",
    "    print(err.message)\n",
    "    seconds_to_wait = wait_time(server_side_problems)\n",
    "    time.sleep(wait_time(seconds_to_wait))\n",
    "    print(f\"waiting {seconds_to_wait} second(s) before new pull request...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "a124beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_and_handle_errors(getting_function, tickers, fields, params):\n",
    "    ticker_and_error = {}\n",
    "    \n",
    "    server_side_problems = 0\n",
    "    \n",
    "    while server_side_problems < 5: \n",
    "        \n",
    "        try:\n",
    "            #if there is only one ticker causing the error should get_and_log perhaps split call into separate tickers?\n",
    "            #fields not avalible should (and I think are) set to NA \n",
    "            new_df, err = getting_function(tickers, fields, params)\n",
    "            return new_df, ticker_and_error\n",
    "        \n",
    "        except ek.EikonError as err:\n",
    "            if err.code ==-1:\n",
    "                #Just general error not specified                        \n",
    "                handle_and_update_server_side_problem(server_side_problems, err)\n",
    "\n",
    "            if err.code == 408: \n",
    "                #HTTP Timeout exception, this just happens frequently... think it can be server side problem\n",
    "                handle_and_update_server_side_problem(server_side_problems, err)\n",
    "            \n",
    "            if err.code == 400 or err.code == 2504: #backend error, eikon suggest waiting this one out \n",
    "                handle_and_update_server_side_problem(server_side_problems, err)\n",
    "            \n",
    "            if err.code == 429:\n",
    "                print(err.message)\n",
    "                print(\"If this error message keeps happening, your subscription has probably collected to much data today\")\n",
    "                #either daily limit is reached or call based limit reached latter can be a problem from get_datas en\n",
    "        \n",
    "    for ticker in tickers:\n",
    "        ticker_and_error[ticker] = err \n",
    "    \n",
    "    return new_df, ticker_and_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "e3079927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_if_criteria_met(df, filename, count):\n",
    "    if not count % 10 or count == -1:\n",
    "        df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "3d336e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_filename(filename):\n",
    "    if filename[-4:] == \".csv\":\n",
    "        return filename\n",
    "    return filename + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "21edab25",
   "metadata": {
    "id": "21edab25"
   },
   "outputs": [],
   "source": [
    "def get_data(lst_of_tickers, fields, params, filename=None):\n",
    "    #(return or save) requested data and (return or save) non-retreived-data \n",
    "    saved = False\n",
    "    saved_df = None\n",
    "    filename = format_filename(filename)\n",
    "    tickers_params_pairs, chosen_function = _divide_pull_request(lst_of_tickers, fields, params)\n",
    "    \n",
    "    for i, (tickers, param ) in enumerate(tqdm(tickers_params_pairs)):  \n",
    "\n",
    "        new_df, ticker_and_error = get_data_and_handle_errors(chosen_function, tickers, fields, param)\n",
    "        \n",
    "      \n",
    "        if saved_df is None:\n",
    "            saved_df = new_df \n",
    "\n",
    "        else:\n",
    "            saved_df = pd.concat([saved_df, new_df])\n",
    "        \n",
    "        save_if_criteria_met(saved_df, filename, i)\n",
    "    \n",
    "    save_if_criteria_met(saved_df, filename,-1)\n",
    "    \n",
    "    return saved_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "f7558ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_timepoints 1\n",
      "number_of_tickers_at_once 4500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17abde25bd67445ca29bc1c69536a3e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instrument</th>\n",
       "      <th>Date</th>\n",
       "      <th>Total Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KAER.VI</td>\n",
       "      <td></td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TIRO.VI</td>\n",
       "      <td></td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000416.SZ</td>\n",
       "      <td>2003-03-31T00:00:00Z</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000416.SZ</td>\n",
       "      <td>2003-06-30T00:00:00Z</td>\n",
       "      <td>11633826.638478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000416.SZ</td>\n",
       "      <td>2003-09-30T00:00:00Z</td>\n",
       "      <td>15210341.911321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>000416.SZ</td>\n",
       "      <td>2021-03-31T00:00:00Z</td>\n",
       "      <td>1494615.220245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>000416.SZ</td>\n",
       "      <td>2021-06-30T00:00:00Z</td>\n",
       "      <td>1389533.190843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>000416.SZ</td>\n",
       "      <td>2021-09-30T00:00:00Z</td>\n",
       "      <td>1170244.523056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>NEDJ.J</td>\n",
       "      <td></td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>SBKJ.J</td>\n",
       "      <td></td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Instrument                  Date    Total Revenue\n",
       "0     KAER.VI                                   <NA>\n",
       "1     TIRO.VI                                   <NA>\n",
       "2   000416.SZ  2003-03-31T00:00:00Z             <NA>\n",
       "3   000416.SZ  2003-06-30T00:00:00Z  11633826.638478\n",
       "4   000416.SZ  2003-09-30T00:00:00Z  15210341.911321\n",
       "..        ...                   ...              ...\n",
       "74  000416.SZ  2021-03-31T00:00:00Z   1494615.220245\n",
       "75  000416.SZ  2021-06-30T00:00:00Z   1389533.190843\n",
       "76  000416.SZ  2021-09-30T00:00:00Z   1170244.523056\n",
       "77     NEDJ.J                                   <NA>\n",
       "78     SBKJ.J                                   <NA>\n",
       "\n",
       "[79 rows x 3 columns]"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_of_tickers = global_financial.index.to_list()[:5]\n",
    "fields = [\"TR.TotalRevenue.Date\",  \"TR.TotalRevenue\"]\n",
    "#Eikon parameters\n",
    "start_date = '2000-01-01'\n",
    "end_date = '2022-04-21'\n",
    "ek_params = {'SDate': start_date, 'EDate': end_date,'Frq': 'FQ', \"Curn\":\"USD\", 'period':\"FQ0\"}\n",
    "\n",
    "df = get_data(lst_of_tickers, fields, ek_params, \"test1\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "e7480644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     None  TR.COMPANYMARKETCAP.DATE  TR.COMPANYMARKETCAP\n",
       " 0  VAR.OL                      <NA>                 <NA>,\n",
       " [{'code': 234,\n",
       "   'col': 1,\n",
       "   'message': \"The '00' is unexpected in formula. A delimiter is probably missing before the lexeme.\",\n",
       "   'row': 0},\n",
       "  {'code': 234,\n",
       "   'col': 2,\n",
       "   'message': \"The '00' is unexpected in formula. A delimiter is probably missing before the lexeme.\",\n",
       "   'row': 0}])"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_of_tickers = global_financial.index.to_list()[:10]\n",
    "fields = ['TR.CompanyMarketCap.Date','TR.CompanyMarketCap']\n",
    "#Eikon parameters\n",
    "start_date = pd.to_datetime('2000-01-01')\n",
    "end_date = pd.to_datetime('2022-04-21')\n",
    "params = {'SDate': start_date, 'EDate': end_date,'Frq': 'D', \"Curn\":\"USD\"}\n",
    "\n",
    "ek.get_data(\"VAR.OL\", fields, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "28f56252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     Instrument                  Date  Company Market Cap\n",
       " 0       KAER.VI  2000-01-03T00:00:00Z    404170472.154094\n",
       " 1       KAER.VI  2000-01-04T00:00:00Z    405939471.405599\n",
       " 2       KAER.VI  2000-01-05T00:00:00Z    406173934.568257\n",
       " 3       KAER.VI  2000-01-06T00:00:00Z    406370925.301055\n",
       " 4       KAER.VI  2000-01-07T00:00:00Z    405191838.750501\n",
       " ...         ...                   ...                 ...\n",
       " 5541    KAER.VI  2022-04-13T00:00:00Z    677775171.437901\n",
       " 5542    KAER.VI  2022-04-14T00:00:00Z    669515341.807237\n",
       " 5543    KAER.VI  2022-04-19T00:00:00Z    671612449.171098\n",
       " 5544    KAER.VI  2022-04-20T00:00:00Z    689576329.666037\n",
       " 5545    KAER.VI  2022-04-21T00:00:00Z     693340423.68749\n",
       " \n",
       " [5546 rows x 3 columns],\n",
       " None)"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ek.get_data(['KAER.VI'], fields,{'SDate': '2000-01-01 00:00:00', 'EDate': '2022-04-21 00:00:00', 'Frq': 'D', 'Curn': 'USD'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ae8030",
   "metadata": {},
   "source": [
    "## Legacy code, perhaps something relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b8d0c2",
   "metadata": {
    "id": "5659be0b"
   },
   "outputs": [],
   "source": [
    "def save_data(file_name, save_per_n_http_request, lst_of_tickers, params):\n",
    "    \n",
    "    non_collected_tickers = []\n",
    "\n",
    "    name_to_index = {}\n",
    "    dfs = {}\n",
    "    for i, possible_key in enumerate([\"stock_data\", \"meta_data\", \"fundamental_data\", \"broker_data\"]):\n",
    "        if params[possible_key]:\n",
    "            name_to_index[possible_key] = i\n",
    "            dfs[possible_key] = []\n",
    "    \n",
    "    partioned_lst_of_tickers = _sub_lists(lst_of_tickers, params[\"limit\"])        \n",
    "    for i, sub_ticker_lst in enumerate(tqdm(partioned_lst_of_tickers, \"saving loop\")):    \n",
    "        \n",
    "        try:\n",
    "            raw_data_dfs = get_data(sub_ticker_lst, params)\n",
    "            \n",
    "            for key in name_to_index:\n",
    "           \n",
    "                dfs[key] = dfs[key] + [raw_data_dfs[name_to_index[key]]]\n",
    "                \n",
    "                \n",
    "                \n",
    "            if not (i % save_per_n_http_request):\n",
    "                for key in name_to_index:\n",
    "                    df = pd.concat(dfs[key], axis=0)\n",
    "                    df = df.reset_index()\n",
    "                    \n",
    "                    df.to_feather(f\"{file_name}_save={i}_type={key}.feather\")\n",
    "                    \n",
    "                    \n",
    "                    dfs[key] = []\n",
    "\n",
    "        except ek.EikonError as err:\n",
    "            for key in name_to_index:\n",
    "                dfs[key] = []\n",
    "                \n",
    "            non_collected_tickers += sub_ticker_lst\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            for key in name_to_index:\n",
    "                dfs[key] = []\n",
    "                \n",
    "            non_collected_tickers += sub_ticker_lst\n",
    "            \n",
    "    #Write crashes to file       \n",
    "    with open(f\"{file_name}.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(non_collected_tickers))\n",
    "    \n",
    "    #Save last data if there are rests\n",
    "    for key in name_to_index:\n",
    "            break\n",
    "            if dfs[key] != []:\n",
    "                df = pd.concat(dfs[key], axis=0)\n",
    "\n",
    "                df = df.reset_index()\n",
    "\n",
    "                #wtfffff\n",
    "                df.to_feather(f\"{file_name}_save={len(partioned_lst_of_tickers)}_type={key}.feather\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "892ee084",
   "metadata": {
    "id": "892ee084",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _time_interval(start_date, end_date):\n",
    "    y0 = int(start_date.split(\"-\")[0])\n",
    "    yn = int(end_date.split(\"-\")[0])\n",
    "    in_between_dates = [f\"{str(year)}-01-01\" for year in range(y0+1,yn,7)]\n",
    "    return [start_date] + in_between_dates  + [end_date]\n",
    "    \n",
    "        \n",
    "#This is code for getting macro timeseries data, as Refinitivs get_data method was hard to work with. \n",
    "def macro_data(lst_of_tickers, ek_get_timeseries_fields, params):\n",
    "        start_and_ends = _time_interval(params[\"SDate\"],params[\"EDate\"])\n",
    "        \n",
    "        tickers_to_serie = {}\n",
    "        for ticker in lst_of_tickers:\n",
    "            tickers_to_serie[ticker] = []\n",
    "            for i in range(len(start_and_ends)-1):\n",
    "                try: \n",
    "                    time_series = ek.get_timeseries(ticker, fields=ek_get_timeseries_fields,\n",
    "                                                    start_date=start_and_ends[i], end_date=start_and_ends[i+1], interval=params[\"interval\"])\n",
    "                                 \n",
    "                except ek.EikonError as err:\n",
    "                    if err.code ==-1:\n",
    "                        time_series = ek.get_timeseries(\"BRT-\", fields=ek_get_timeseries_fields, start_date=start_and_ends[i], end_date=start_and_ends[i+1],interval=params[\"interval\"])\n",
    "                        time_series[ek_get_timeseries_fields] = np.nan\n",
    "                        \n",
    "                    if err.code ==  2504:\n",
    "                        print(\"backend error\")\n",
    "                        time.sleep(2)\n",
    "                        time_series = ek.get_timeseries(ticker, fields=ek_get_timeseries_fields,\n",
    "                                                    start_date=start_and_ends[i], end_date=start_and_ends[i+1], interval=params[\"interval\"])\n",
    "                        \n",
    "                tickers_to_serie[ticker] = tickers_to_serie[ticker] + [time_series]\n",
    "            \n",
    "            tickers_to_serie[ticker] = pd.concat(tickers_to_serie[ticker], axis=0)\n",
    "            \n",
    "        return tickers_to_serie"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "data_collection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
